@inproceedings{NIPS2011_33ceb07b,
author = {Grave, Edouard and Obozinski, Guillaume R and Bach, Francis},
booktitle = {Advances in Neural Information Processing Systems},
editor = {Shawe-Taylor, J and Zemel, R and Bartlett, P and Pereira, F and Weinberger, K Q},
publisher = {Curran Associates, Inc.},
title = {{Trace Lasso: a trace norm regularization for correlated designs}},
url = {https://proceedings.neurips.cc/paper/2011/file/33ceb07bf4eeb3da587e268d663aba1a-Paper.pdf},
volume = {24},
year = {2011}
}

@INPROCEEDINGS{7877209,  author={Phaisangittisagul, Ekachai},  booktitle={2016 7th International Conference on Intelligent Systems, Modelling and Simulation (ISMS)},   title={An Analysis of the Regularization Between L2 and Dropout in Single Hidden Layer Neural Network},   year={2016},  volume={},  number={},  pages={174-179},  doi={10.1109/ISMS.2016.14}}

@INPROCEEDINGS{7877209,  author={Phaisangittisagul, Ekachai},  booktitle={2016 7th International Conference on Intelligent Systems, Modelling and Simulation (ISMS)},   title={An Analysis of the Regularization Between L2 and Dropout in Single Hidden Layer Neural Network},   year={2016},  volume={},  number={},  pages={174-179},  doi={10.1109/ISMS.2016.14}}

@article{https://doi.org/10.1002/bimj.201500115,
abstract = {We study bias arising as a result of nonlinear transformations of random variables in random or mixed effects models and its effect on inference in group-level studies or in meta-analysis. The findings are illustrated on the example of overdispersed binomial distributions, where we demonstrate considerable biases arising from standard log-odds and arcsine transformations of the estimated probability , both for single-group studies and in combining results from several groups or studies in meta-analysis. Our simulations confirm that these biases are linear in $\rho$, for small values of $\rho$, the intracluster correlation coefficient. These biases do not depend on the sample sizes or the number of studies K in a meta-analysis and result in abysmal coverage of the combined effect for large K. We also propose bias-correction for the arcsine transformation. Our simulations demonstrate that this bias-correction works well for small values of the intraclass correlation. The methods are applied to two examples of meta-analyses of prevalence.},
author = {Bakbergenuly, Ilyas and Kulinskaya, Elena and Morgenthaler, Stephan},
doi = {https://doi.org/10.1002/bimj.201500115},
journal = {Biometrical Journal},
keywords = { Meta-analysis, Overdispersion, Random effects, Transformation bias,Intracluster correlation},
number = {4},
pages = {896--914},
title = {{Inference for binomial probability based on dependent Bernoulli random variables with applications to meta-analysis and group level studies}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201500115},
volume = {58},
year = {2016}
}

@article{lecun-mnisthandwrittendigit-2010,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}


@misc{martin2018implicit,
      title={Implicit Self-Regularization in Deep Neural Networks: Evidence from Random Matrix Theory and Implications for Learning}, 
      author={Charles H. Martin and Michael W. Mahoney},
      year={2018},
      eprint={1810.01075},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
